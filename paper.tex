\documentclass[review,onefignum,onetabnum]{siamonline190516}

\usepackage{graphicx}
\usepackage{lineno}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\usepackage{epstopdf}
\ifpdf
  \DeclareGraphicsExtensions{.eps,.pdf,.png,.jpg}
\else
  \DeclareGraphicsExtensions{.eps}
\fi

\usepackage{enumitem}
\setlist[enumerate]{leftmargin=.5in}
\setlist[itemize]{leftmargin=.5in}
\include{snippets}

\graphicspath{ {./src/} }
% \linespread{2.0}
\begin{document}


% \begin{frontmatter}
\title{Shape Prior Segmentation Guided by Harmonic Beltrami Signature}

\author{
    Chenran Lin\thanks{Department of Mathematics, The Chinese University of Hong Kong, Hong Kong (\email{crlin@math.cuhk.edu.hk})}
    \and
    Lok Ming Lui\thanks{Department of Mathematics, The Chinese University of Hong Kong, Hong Kong (\email{lmlui@math.cuhk.edu.hk})}
}
% \headers{Harmonic Beltrami Signature}{Chenran Lin, and Lok Ming Lui}

\maketitle

\begin{abstract}
    
\end{abstract}

\begin{keywords}
    shape prior, segmentation, Harmonic Beltrami Signature
\end{keywords}

\section{Introduction}
\label{intro}


\section{Related works}\label{related work}


\section{Theoretical basis}\label{background}
\subsection{Quasi-conformal mapping and Beltrami equation}
A complex function $f: \Omega \subset \C \rightarrow \C$ is said to be \textit{quasi-conformal} associated to $\mu$ if $f$ is orientation-preserving and satisfies the following \textit{Beltrami equation}:
\begin{equation}\label{beltrami eq}
    \Part{f}{\overline{z}} = \mu(z) \Part{f}{z}
\end{equation}
where $\mu(z)$ is a complex-valued Lebesgue measurable function satisfying $\norm{\mu}_\infty < 1$. More specifically, this $\mu: \Omega \rightarrow \D$ is called the \textit{Beltrami coefficient} of $f$
\begin{equation}\label{mu def}
    \mu = \frac{f_{\overline{z}}}{f_{z}}
\end{equation}

In terms of the metric tensor, consider the effect of the pullback under $f$ of the Euclidean metric $ds^2_E$, the resulting metric is given by:
\begin{equation}
    f^*(ds^2_E) = \abs{\Part{f}{z}}^2 \abs{dz + \mu(z)d\overline{z}}^2
\end{equation}
which, relative to the background Euclidean metric $dz$ and $d\overline{z}$, has eigenvalue $(1+\abs{\mu})^2 \abs{\Part{f}{z}}^2$ and $(1-\abs{\mu})^2 \abs{\Part{f}{z}}^2$. 

Therefore, inside the local parameter domain around some point $p$, $f$ can be considered as a map composed of a translation to $f(p)$ together with the multiplication of a stretch map $S(z) = z + \mu(p)\overline{z}$ and conformal function $f_z(p)$, which may be expressed as follows:
\begin{equation}\label{local f}
    f(z) =  f(p)+S(z)f_z(p) = f(p)+(z+\mu(p)\overline{z})f_z(p).
\end{equation}
$S(z)$ makes $f$ map a small circle to a small ellipse and all the conformal distortion of $f$ is caused by $\mu$. To form $\mu(p)$, we can determine the angles of the directions of maximal magnification and shrinkage and the amount of them as well. Specially, the angle of maximal magnification is $\arg(\mu(p))/2$ with magnifying factor $1+\abs{\mu(p)}$; the angle of maximal shrinkage is the orthogonal angle $\arg(\mu(p))/2 - \pi/2$ with shrinkage factor $1-\abs{\mu(p)}$. The distortion or dilation is given by:
\begin{equation}
    K = \frac{1+\abs{\mu(p)}}{1-\abs{\mu(p)}}.
\end{equation}
Thus, the Beltrami coefficient $\mu$ gives us important information about the properties of the map (see figure \ref{fig3}) and $\mu$ is a measure of non-conformality. In particular, the map $f$ is conformal around a small neighborhood of $p$ when $\mu(p)=0$ and if $\mu(z)=0$ everywhere on $\Omega$, $f$ us called \textit{conformal} or \textit{holomorphic} on $\Omega$.

\begin{figure}
    \begin{center}
        \includegraphics[width=7.6cm]{background_bc1.png}
    \end{center}
    \caption{Quasi-conformal maps infinitesimal circles to ellipses. The Beltrami coefficient measure the distortion or dilation of the ellipse under the QC map.}
    \label{fig3}
\end{figure}


Note that there is a one-to-one correspondence between the quasi-conformal mapping $f$ and its Beltrami coefficient $\mu$. Given $f$, there exists a Beltrami coefficient $\mu$ satisfying the Beltrami equation by equation (\ref{mu def}). Conversely, the following theorem states that given an admissible Beltrami coefficient $\mu$, there always exists an quasi-conformal mapping $f$ associating with this $\mu$.

\begin{theorem}[Measurable Riemannian Mapping Theorem]\label{Measurable Riemannian Mapping Theorem}
    Suppose $\mu : \C \rightarrow \C$ is Lebesgue measurable satisfying $\norm{\mu}_\infty <1$; then, there exists a quasi-conformal homeomorphism $f$ from $\C$ onto itself, which is in the Sobolev space $W_{1,2}(\C)$ and satisfies the Beltrami equation in the distribution sense. The associated quasi-conformal homeomorphism $f$ is unique up to a Mobi\"us transformation. Furthermore, by fixing $0$, $1$ and $\infty$, the $f$ is uniquely determined.
\end{theorem}

\subsection{LBS}

\subsection{HBS}

\subsection{Euler-Lagrange equation}

\section{Proposed segmentation model}\label{main}
In this section, we describe our proposed shape prior segmentation model guided by HBS.

\subsection{Beltrami coefficient segmentation model}
At the beginning, we need to discribe Beltrami coefficient segmentation, which is the fundamentation of our HBS segmentation model. 

Suppose $D, D' \in \C$ are two regions, $I: D' \rightarrow \R$ is an image and $J: D \rightarrow \R$ is a binary template image. $J$ is called the \textit{topological prior image} defined as
\begin{equation}
    J(x) = \begin{cases}
        1, & x \in R,              \\
        0, & x \in D \setminus R,
    \end{cases}
\end{equation}
where $R \subset D$ is the object region of $J$. The basic idea of the segmentation model proposed by Chan \etal \cite{} is to deform this simple template $J$ to extract the target region $\Omega = f_\mu(R)$ from $I$ by a quasiconformal mapping $f_\mu: D \rightarrow D'$. Note that in most cases, $D = D'$ is a rectangle domain.

This model can be formulated as the following energy functional:
\begin{equation}\label{bc seg model}
    \min_{\mu} E_{\text{BC}}(\mu, c_1, c_2) = \min_{\mu} \int_D (I \circ f_\mu - J_{c_1,c_2})^2 + \alpha \abs{\mu}^2 + \beta \abs{\nabla \mu}^2 + \gamma \abs{u}^2 + \delta \abs{\nabla u}^2,
\end{equation}
where $u = f_\mu - Id$, $\mu: \Omega \rightarrow \C$ is the Beltrami coefficient of $f_\mu$,  $\alpha, \beta, \gamma, \delta \ge 0$ are weight parameters and $J_{c_1, c_2}$ is a generalized template image defined as
\begin{equation}
    J_{c_1, c_2}(x) = \begin{cases}
        c_1, & x \in R,              \\
        c_2, & x \in D \setminus R.
    \end{cases}
\end{equation}

The first item of $E_{\text{BC}}$ measures the difference between the deformed image $I \circ f_\mu$ and the template image $J_{c_1, c_2}$. The second item limits the magnitude of $\mu$ since $\abs{\mu} < 1$ if and only if $f_\mu$ is quasiconformal, which then ensures the bijectivity of $f_\mu$. The last three items are the regularization terms, which are used to control the smoothness of $f_\mu$.

\subsection{HBS segmentation model}
The HBS proposed in \cite{} is a powerful signature of 2D simply-connected shapes and  it represents the shape features by a complex function $B: \D \rightarrow \C$. More precisely, the HBS $B$ of the shape $\Omega_B \subset \C$ is the Beltrami coefficient of a special harmonic function $H$ such that $H(\D) = \Omega_B$. The HBS $B$ is invariant under translation, rotation and scaling, which means it can be treated as high-level shape prior with invariant geometric information under these transformations. As is well-known, translation, rotation and scaling are very common in image processing and we have good reason to believe that the HBS and the inherent invariant features it contains can effectively guide image segmentation. Inspired by this, we propose this novel HBS segmentation model.

Meanwhile, the primary objective of the segmentation model \ref{bc seg model} is to locate a suitable Beltrami coefficient $\mu$ and the corresponding quasiconformal function $f_\mu$, then the target region is $\Omega = f_\mu(R)$. 

The triplets $(B, H, \D)$ of the HBS and $(\mu, f_\mu, R)$ of model \ref{bc seg model} exhibit extreme high correlation, which implies that the HBS can be naturally integrated into this model. However, there are several differences:
\begin{enumerate}
    \item $B$ is defined on $\D$ while $\mu$ is defined on $D$. To solve this, we require $D \supset \D$ and extend $B$ to $D$ by $0$, that is
          \begin{equation}\label{mu_B}
              \mu_B = \begin{cases}
                  B, & z \in \D,              \\
                  0, & z \in D \setminus \D.
              \end{cases}
          \end{equation}
          
    \item $H$ is a quasiconformal harmonic function while $f_\mu$ is only quasiconformal. Hence we constrain the value $\Delta f_\mu$ to be very close to $0$.
          
    \item The shape can be represented as $\Omega_B = H(\D)$ in the HBS while the segmentation result is $\Omega = f_\mu(R)$ in model \ref{bc seg model}. Therefore, we fix the object region $R$ of template $J$ always to be $\D$.
\end{enumerate}

With above modifications, $\mu$ can be almost considered as a HBS. We can compare  $\mu$ and $B$ directly by $L_2$ norm $\norm{\mu - \mu_B}^2_2$. Therefore, the HBS segmentation model is formulated as follows:
\begin{equation}\label{hbs seg model}
    \begin{split}
        \min_{\mu} E_{\text{HBS}}(\mu, B, c_1, c_2) = 
        \min_{\mu} \int_D 
        & (I \circ f_\mu - J_{c_1,c_2})^2 
        + \alpha \abs{\mu}^2 + \beta \abs{\nabla \mu}^2 
        + \gamma \abs{u}^2 \\
        & + \delta \abs{\nabla u}^2
        + \lambda \abs{\mu - \mu_B}^2 + \eta \abs{\Delta u}^2.
    \end{split}
\end{equation}
The first five terms come from model \ref{bc seg model} directly and play the same roles as before. The sixth term measures the similarity of $\mu$ and $B$. And the last term with a big penalty parameter $\eta$ is a soft constrain that $f_\mu$ is harmonic.

The term $\int_D \abs{\mu - \mu_B}^2$ is crucial for model \ref{hbs seg model}. Note that the template $J$ is fixed, the HBS $B$ contains all shape prior informations by this term. $B$ is corresponding to a unique shape $\Omega_B$ up to translation, rotation and scaling. The smaller this term is, the more similar the segmentation result $\Omega = f_\mu(\D)$ and $\Omega_B$ are, which provides a simple yet effective method to utilize prior information for guiding the segmentation process.

The existence of the minimizer of model \ref{hbs seg model} over $\mu$ is guaranteed by the following theorem.
\begin{theorem}\label{existence}
    The energy functional $E_{\text{HBS}}$ in model \ref{hbs seg model} has a minimizer in $\mathcal{A}^M_\epsilon \subset C^1(D)$, where
    \begin{equation*}
        \mathcal{A}^M_\epsilon = \{ \mu \in C^1(D) : \norm{D \mu}_\infty \le M, \norm{\mu}_\infty \le 1 - \epsilon \},
    \end{equation*}
    for some $M > 0$ and $\epsilon \in (0, 1)$.
\end{theorem}

\begin{proof}
    Following a similar argument in \cite{}, we can show that $\mathcal{A}^M_\epsilon$ is Cauchy complete and totally bounded, and hence compact. The three terms containing $\mu$, $\int_D \abs{\mu}^2$, $\int_D \abs{\nabla \mu}^2$ and $\int_D \abs{\mu - \mu_B}^2$, are obviously continuous over $\mu$. Also, according to the Beltrami holomorphic flow and Bojarski theorem, the associated quasiconformal map $f_\mu$ varies continuously (smoothly) under a continuous (smooth) variation of $\mu$. Hence, the other four terms are continuous over $\mu$ as well. Since $E_\text{HBS}$ is continuous on the compact set $\mathcal{A}^M_\epsilon$, $E_\text{HBS}$ has a minimizer in it.
\end{proof}

Similar with that mentioned in \cite{}, the smaller $\epsilon$ is, the more geometric distortion is allowed, and the deformed contour get closer to real object boundary. However, small $\epsilon$ increses the difficulty to find the minimizer, which is a trade-off between the accuracy and the efficiency. Meanwhile, the bigger $M$ is, the smoother the deformed contour is, but we get less accurate segmentation result. We can choose $\epsilon$ and $M$ according to the prior information of the given shape.

\section{Numerical algorithm}
In practice, a digital image consists of many pixels and can be discreted by a triangular mesh $(V, E, F)$, where $V \subset D$ is the set of vertices, $E$ is the set of edges between vertices and $F$ is the set of triangle faces formed by edges. The deform function $f_{\mu_V}: V \rightarrow D$ is piecewise linear on each face and $f_{\mu_V}|_{\partial D} = Id$. The first derivative of $f_{\mu_V}$ is piecewise constant and so the Beltrami coefficient $\mu_F: F \rightarrow \C$ is a constant on each face. Then we compute $\mu_V: V \rightarrow \C$ by taking the average of $\mu_F$ on the faces sharing the same vertex. We do the same thing to get $\mu_{B,V}$. Although the input images are only defined on $V$, we treat it as a continuous functions $I, J: D \rightarrow \R$ through interpolation for the sake of convenience in the discussion. Hence, the deformed image $I \circ f_{\mu_V}: V \rightarrow \R$ can be achieved. As the result, the discrete HBS segmentation model is as follows:
\begin{equation}\label{discrete hbs seg model}
    \begin{split}
        \min_{\mu_V} E_{\text{DHBS}}(\mu_V, B, c_1, c_2) = 
        \min_{\mu_V} \sum_{v \in V}
        & (I \circ f_{\mu_V} - J_{c_1,c_2})^2 
        + \alpha \abs{\mu_V}^2 + \beta \abs{\nabla \mu_V}^2 
        + \gamma \abs{u_V}^2 \\
        & + \delta \abs{\nabla u_V}^2
        + \lambda \abs{\mu_V - \mu_{B,V}}^2 + \eta \abs{\Delta u_V}^2.
    \end{split}
\end{equation}

However, this model implies a constraint, $\mu_V = \frac{\partial f_{\mu_V}}{\partial \bar{z}} / \frac{\partial f_{\mu_V}}{\partial z}$, which presents a significant challenge during searching the minimizer. To solve this, we disconnect the strong coupling between $\mu_V$ and $f_{\mu_V}$ and set another Beltrami coefficient $\nu_{V}$ without direct relation with $f_{\mu_V}$ as an alternative, which induces a weak HBS segmentation model:
\begin{equation}\label{weak discrete hbs seg model}
    \begin{split}
        \min_{\mu_V, \nu_V} E_{\text{WHBS}}(\mu_V, \nu_V, B, c_1, c_2) = 
        & \min_{\mu_V, \nu_V} \sum_{v \in V}
        (I \circ f_{\mu_V} - J_{c_1,c_2})^2 
        + \alpha \abs{\nu_V}^2 + \beta \abs{\nabla \nu_V}^2 
        + \gamma \abs{u_V}^2 \\
        & + \delta \abs{\nabla u_V}^2
        + \lambda \abs{\nu_V - \mu_{B,V}}^2 + \eta \abs{\Delta u_V}^2 + \tau \abs{\nu_V - \mu_V}^2.
    \end{split}
\end{equation}
Here we replace all $\mu_V$ by $\nu_V$ in 2nd, 3th and 6th terms of model \ref{discrete hbs seg model} and add a new term $\tau \abs{\nu_V - \mu_V}^2$ to handle the difference between $\mu_V$ and $\nu_V$, where $\tau > 0$ is a big penalty parameter. If $\nu_V = \mu_V$, $E_{\text{WHBS}}$ will degenerate to $E_{\text{DHBS}}$. This modification allows us to split the original problem into 2 parts and we call them \textbf{$\mu$ subproblem}
\begin{equation}\label{mu subproblem}
    \min_{\mu_V} E_{\mu}(\mu_V, c_1, c_2) = 
    \min_{\mu_V} \sum_{v \in V}
    (I \circ f_{\mu_V} - J_{c_1,c_2})^2 
    + \gamma \abs{u_V}^2 
    + \delta \abs{\nabla u_V}^2
    + \eta \abs{\Delta u_V}^2,
\end{equation}
and \textbf{$\nu$ subproblem}
\begin{equation}\label{nu subproblem}
    \min_{\nu_V} E_{\nu}(\mu_V, \nu_V, B) = 
    \min_{\nu_V} \sum_{v \in V}
    \alpha \abs{\nu_V}^2 + \beta \abs{\nabla \nu_V}^2 
    + \lambda \abs{\nu_V - \mu_{B,V}}^2 + \tau \abs{\nu_V - \mu_V}^2.
\end{equation}

After such separation, these two subproblem has gained clearer and more practical meanings. The core of $\mu$ subproblem is to find the deform map $f_{\mu_V}$ according to the pixel level difference as well as other regularizations, then $\mu_V$ is achieved naturally. While the target of $\nu$ subproblem is to normalize the Beltrami coefficient $\mu_V$ from the last step under shape prior information for further segmentation. The soft constrain term $\abs{\nu_V - \mu_V}$ is the bridge to connect these two processes. Therefore, we can solve subproblems alternatively until they converge, which then gives the solution of original optimization problem \ref{discrete hbs seg model}. More specifically, suppose $\mu_{V,n}$ and $\nu_{V,n}$ is obtained in $n$-th iteration, then $\mu_{V,n+1}$ and $\nu_{V,n+1}$ can be computed by
\begin{equation}
    \mu_{V,n+1} = \argmin_{\mu_V} E_\mu(\mu_V, c_1, c_2),
\end{equation}
\begin{equation}
    \nu_{V,n+1} = \argmin_{\nu_V} E_\nu(\mu_{V,n+1},\nu_V, B).
\end{equation}
The total algorithm is summarized in algorithm \ref{main alg}.

\subsection{Solving $\mu$ subproblem}
Note that there are the other two input variables $c_1$ and $c_2$ in $E_\mu$. Compared to solving for multiple variables simultaneously, a simpler and more common choice is to determine them in advance. Given $f_{\mu_{V,n}}$, it can be regarded as another optimization problem and we can compute the minimizers explicitly by
\begin{equation}\label{mu c1 c2}
    c_1 = \frac{\sum_{v \in V \cap \D} I \circ f_{\mu_{V,n}}}{\sharp (V \cap \D)}, \quad
    c_2 = \frac{\sum_{v \in V \setminus \D} I \circ f_{\mu_{V,n}}}{\sharp (V \setminus \D)},
\end{equation}
where $\sharp$ means the number of vertices inside the set. Except in necessary cases, we will omit all occurrences of $c_1$ and $c_2$ in the following discussion.

Even theorem \ref{existence} ensure the existence of minimizer, excessively large deformations can still burden the algorithm, leading to fluctuating segmentation results and long computation time. Instead of directly calculating $f_{\mu_{V,n+1}}$, we attempt to compute a smaller deformation based on the previous segmentation result and use a sequence of small deformations to represent the desired $f_{\mu_{V,n+1}}$
\begin{equation}
    f_{\mu_{V,n+1}} = g_{n+1} \circ f_{\mu_{V,n}} = g_{n+1} \circ \cdots \circ g_1 \circ f_{\mu_{V,0}},
\end{equation}
where $g_k: D \rightarrow D$. Since $f_{\mu_{V,n}}$ is quasiconformal then bijective, $f_{\mu_{V,n}}^{-1}$ exists, we  have
\begin{equation}\label{mu 1st term approx v}
    \sum_{v \in V} (I \circ g_{n+1} \circ f_{\mu_{V,n}} - J)^2
    = \sum_{v \in f_{\mu_{V,n}}(V)} (I \circ g_{n+1} - J \circ f_{\mu_{V,n}}^{-1})^2 
    \approx \sum_{v \in V} (I \circ g_{n+1} - J_n)^2,
\end{equation}
where $J_n = J \circ f_{\mu_{V,n}}^{-1}$ is the deformed template image by $f_{\mu_{V,n}}$ and is the temporary segmentation result of the last iteration. The approximate equality is due to the acceptable interpolation error, which will decreases as the image resolution increases. Furthermore, this term can be expanded by a first-order Taylor series
\begin{equation}\label{mu 1st term taylor}
    \sum_{v \in V} (I \circ g_{n+1} - J_n)^2 
    \approx \sum_{v \in V} \abs{I - J_n + \nabla I \cdot h_{n+1}}^2,
\end{equation}
where $h_{n+1} = g_{n+1} - Id$. 

Since $u_{V,n+1} = (h_{n+1} - f_{\mu_{V,n}}^{-1} + Id) \circ f_{\mu_{V,n}}$, the same interpolation approximation in \ref{mu 1st term approx v} can be also applied to the other regular terms of $E_\mu$ in \ref{mu subproblem}. Finally, $\mu$ subproblem can be rewritten as:
\begin{equation}
    \min_h E_\mu (h, J)
    = \min_h \sum_{v \in V} \abs{I - J + \nabla I \cdot h}^2 
    + \gamma \abs{h}^2
    + \delta \abs{\nabla h}^2 
    + \eta \abs{\Delta h}^2.
\end{equation}
The minimizer satisfies following PDE according to Euler-Langrange equation
\begin{equation}\label{mu problem pde}
    (I-J) \nabla I + \nabla I^2 \cdot h + \gamma h - \delta \Delta h + \eta \Delta^2 h = 0,
\end{equation}
subject to $h = 0$ on $\partial D$. We mark the solution of \ref{mu problem pde} as $h_{n+1}$ and the deform function is
\begin{equation}\label{mu deform function f}
    f^*_{\mu_{V,n+1}} = (h_{n+1} + Id) \circ f_{\mu_{V,n}}.
\end{equation}
Then the Beltrami coefficient $\mu_{V,n}$ can be computed on the triangular mesh by
\begin{equation}\label{mu mu}
    \mu_{V,n+1}(v) = \frac{\partial f^*_{\mu_{V,n+1}}}{\partial \bar{z}}(v) \bigg / \frac{\partial f^*_{\mu_{V,n+1}}}{\partial z}(v),
\end{equation}
To avoid some numerical errors, we designate $\mu_{V,n}(v) = 0$ if $\frac{\partial f^*_{\mu_{V,n}}}{\partial z}(v) = 0$ for some $v \in V$.

Besides, we also need $\abs{\mu_{V,n}(v)} < 1$ for all $v \in V$ to guarante the deform function is quasiconformal, so an additional truncation $T$ is applied to those points that are to large as
\begin{equation}\label{mu truncate}
    T(\mu)(v) = \begin{cases}
        \mu(v),                                  & \abs{\mu(v)} < 1 - \epsilon,    \\
        \frac{1 - \epsilon}{\abs{\mu(v)}}\mu(v), & \abs{\mu(v)} \ge 1 - \epsilon,
    \end{cases}
\end{equation}
where $\epsilon$ is a small positive number. So far, we have addressed $\mu$ subproblem and obtained the desired $\mu_{V,n+1}$.

\subsection{Solving $\nu$ subproblem}
As mentioned before, $\nu$ subproblem \ref{nu subproblem} essentially involves refining the solution $\mu_{V,n+1}$ obtained from the previous step. We apply the Euler-Langrange equation to $E_\nu$ with respect to $\nu_V$:
\begin{equation}\label{nu problem pde}
    \alpha \nu_V - \beta \Delta \nu_V + \lambda (\nu_V - \mu_{B,V}) + \tau (\nu_V - \mu_{V,n+1}) = 0,
\end{equation}
subject to $\nu_V = 0$ on $\partial D$. The result of this PDE is $\nu_{V,n+1}$, which solves subproblem \ref{nu subproblem}. Note that we also truncate it by $T$ as \ref{mu truncate}.

By LBS method, we reconstruct the corresponding refined deform function $f_{\mu_{V,n+1}}$ from $\nu_{V,n+1}$ with boundary condition $f_{\mu_{V,n+1}} = Id$ on $\partial D$. It, rather than the $f_{\mu_{V,n+1}}^*$ in \ref{mu deform function f}, induces the temporary segmentation result $J_{n+1} = J \circ f_{\mu_{V,n+1}}^{-1}$ and then is used in next iteration.


\begin{algorithm}[H]
    \caption{HBS segmentation algorithm}
    \label{main alg}
    \begin{algorithmic} 
        \STATE \textbf{Inputs:} Rectangle domain $D \subset \C$, the image to be segmented $I: D \rightarrow \R$, unit disk template $J: D \rightarrow \R$, HBS $B: \D \rightarrow \C$, max iteration times $N$, stop precision $\epsilon$ and other model parameters.
        \STATE \textbf{Initialize:} Build triangle mesh $(V, E, F)$ on $D$ and compute $\mu_{B,V}$ form $B$.
        \STATE Let $n=1$ and $f_{\mu_{V,1}} = Id$.
        \WHILE{$n < N$}
        \STATE Compute $c_1$ and $c_2$ by \ref{mu c1 c2} and then $J_n = J \circ f_{\mu_{V,n}}$.
        \STATE Solve \ref{mu problem pde} and get $h_{n+1}$.
        \STATE Compute $f^*_{\mu_{V,n+1}}$ by \ref{mu deform function f}.
        \STATE Compute $\mu_{V,n+1}$ by \ref{mu mu}.
        \STATE Solve \ref{nu problem pde} and get $\nu_{V,n+1}$.
        \STATE Compute $f_{\mu_{V,n+1}}$ by LBS method.
        \IF{$\norm{f_{\mu_{V,n+1}} - f_{\mu_{V,n}}}_2 < \epsilon$}
        \STATE Break.
        \ENDIF
        \STATE Let $n = n+1$.
        \ENDWHILE
        \RETURN Segmentation result $f_{\mu_{V,n+1}}(\D)$.
    \end{algorithmic}
\end{algorithm}



\section{Experimental result}\label{resul}
In this section, we demonstrate the effectiveness of the proposed HBS segmentation model through different experimental results. Our experiments are implemented using MATLAB R2014a running on 4-way Intel(R) Xeon(R) Gold 6230 processors with 80 cores at 2.10GHz base frequency and 1024 GB RAM under Ubuntu 18.04LTS 64-bit operating system.

\subsection{Binary images}
Deformation of the target object due to various reasons such as image corruption, object occlusion, etc., is very common. In such cases, prior information can greatly assist us in making accurate segmentations. By utilizing HBS as the prior, the proposed segmentation model is aware of the approximate shape of the target object beforehand, leading to improved performance. 

To illustrate this more intuitively, we have constructed a series of simple binary images to validate our model and display the results in Figure \ref{exp1}. For each row, the 1st column is the original shape, the 2nd column is the template shape, the 3rd column is the HBS corresponding to the template shape, the 4th column is the segmentation result without HBS and the 5th column is the segmentation result of our proposed model. Before analyzing the results, it is important to clarify some points and we will use them in the following experiments unless otherwise specified.
\begin{enumerate}
    \item The template provided in the 2nd column is not the $J$ in our model, which has been fixed as the unit disk. Here the template shape is solely used to compute HBS and will not be fed into the model. We show them to help our humans to have a visual understanding of the prior information.
    \item Exactly speaking, it is the magnitude of $\mu_{B,V}$ shown in the 3rd column.
    \item The green line in 4th and 5th column is the segmentation boundary.
    \item The segmentation result without HBS is obtained by setting $\lambda = \eta = 0$ of model \ref{hbs seg model}, which then is equivalent to the Beltrami coefficient segmentation model \ref{bc seg model}. We also use the unit disk as $J$.
\end{enumerate}

Let's look back on Figure \ref{exp1}, from which we can preliminarily obtain the following information:
\begin{enumerate}
    \item The HBS played a significant role in the low-quality image segmentation. We made some modifications to basic geometric shapes, resulting in them lacking certain parts or having additional parts. Under the guidance of HBS, our model essentially disregarded the impact of these variations and provided satisfactory segmentation, which almost matched the given template. While the segmentation result without HBS is much more faithful to the actual shape boundaries.
    \item The proposed model can segment both the simply-connected and multi-connected images and then give simply-connected results. Although the HBS is the signature of simply-connected shapes, our model works well on multi-connected images in 3rd and 4th rows.
    \item The proposed model does not impose any requirements on the position, size, or orientation of the target object in the image. The HBS is invariant under translation, rotation and scaling and our model inherited this feature. With the same HBS, 1st and 2nd row are rectangles in different size and our model can segment them correctly. Similarly, 3rd and 4th rows are triangles in different orientation.
    \item The proposed model tolerates reasonable discrepancies between the prior information and the actual image. In the 5th row, the segmentation result is acceptable when the template is a circle and the image is close to a ellipse.
    \item The proposed model effectively utilizes the prior information provided by the given template rather than simply extracting some basic geometric properties. In 2nd row, our model handle convex and concave parts at the same time. We will further demonstrate this in the following experiment.
\end{enumerate}

\begin{figure}
    \begin{center}
        \includegraphics[width=15.5cm]{src/exp1.png}
    \end{center}
    \caption{Segmentation results of binary images.}
    \label{exp1}
\end{figure}

We will further observe the impact of different templates on the segmentation results from Figure \ref{exp2}. The meanings of each column is the same with Figure \ref{exp1}. The original image is similar to a hexagon, and we used hexagon, circle, diamond and square templates to segment it, with the results shown in 1st, 2nd, 3rd and 4th row respectively. We can find that all of the segmentation results preserve some shape characteristics of their corresponding templates but their performances differ significantly. The 1st row is the best, 2nd row is still acceptable but 3rd and 4th rows are far from accurate. That indicates our proposed method is highly sensitive to the given template. A precise template gives a prefect segmentation result, while an unsuitable template leads a terrible one. But on the other hand, it also implies our model has a certain level of understanding of the prior information.

\begin{figure}
    \begin{center}
        \includegraphics[width=15.5cm]{src/exp2.png}
    \end{center}
    \caption{Segmentation results under different templates.}
    \label{exp2}
\end{figure}

\subsection{Natural images}
The experimental results on binary images demonstrate that our model can effectively utilize prior information to segment partially damaged target object. However, we are far from satisfied with this and we extend the model's application to real-world images.

Figure \ref{exp3} presents some results on natural images. As before, original image, template, HBS, segmentation without HBS and segmentation with HBS are sequentially displayed in columns 1 to 5 of each row. The 1st row is a grayscale image with a bear in grass. Without HBS, the model only relies on the intensity of grayscale values to determine the shape boundaries, which results in the top boundary being limited to the brighter nose and forehead, while the bottom boundary appears jagged due to the grass. When HBS is specified, even the circle is not a very suitable template, it helps our proposed HBS segmentation model to generate a much smoother and more complete result. The other 3 images are color images, which need to be compressed RGB to grayscale before applying our model. The result in 2nd row demonstrates no matter how many pieces the target object is seprated to, our model can segment it as a simply-connected entity, just like what it does on binary images. The 3rd row represents similar but a more practical scenario, occlusion, and our model successfully and accurately identifies the white paper behind pens. In the 4th row, our model also completely locates the signboard partially covered under the dust. 

\begin{figure}
    \begin{center}
        \includegraphics[width=15.5cm]{src/exp3.png}
    \end{center}
    \caption{Segmentation results of natural images.}
    \label{exp3}
\end{figure}

\subsection{Shape prior of complex images}
We have illustrated that shape prior can help segmentation but how to obtain shape prior still remains a challenging problem. In the previous experiments, the templates fed into our model are always simple geometric shapes such as circle, triangle and so on. Although these simple shapes allow our model to achieve good results, they actually conceals its enormous potential.

We can describe basic geometric shapes with simpler signatures like area, density, curvature, circularity and so on. But when the complexity of the object reaches a certain level, it becomes difficult for traditional signatures to fully represent the shape information, while the HBS demonstrates its capacity. The HBS uses a simple and unified form to fully describe the characteristics of the shapes, exhibiting a range of wonderful properties and enabling reconstruction of the original shapes. Apart from extracting the shape boundaries, the HBS does not require any additional preprocessing to the image, which makes it extremely easy to find common features from a large number of images of the same object class. Figure \ref{exp5} provides an example of computing shape prior of brains. For 1-6 rows, 1st column is the image of brain with green line as brain boundary, 2nd column is its HBS and 3rd column is the reconstructed brain from HBS. We can observe that there is a small gap between the given boundary in 1st column and reconstructed brain in 3rd column, which actually is due to the resolution. But it does not affect our segmentation since the reconstructed results are not used in our segmentation model. Besides, this gap will decrease when the resolution increases as mentioned in \cite{}.
\begin{figure}
    \begin{center}
        \includegraphics[width=9cm]{src/exp5.png}
    \end{center}
    \caption{HBS of brains and their mean HBS.}
    \label{exp5}
\end{figure}

Then we directly calculate the algebraic mean of the HBS of above 6 brains, called the mean HBS, and also reconstruct a brain from the mean HBS, called the mean shape. They are respectively shown in 2nd and 3rd column of 7th row. Even though the relationship between HBS and the shape is challenging to explain, we can still observe the following features from the first 6 rows:
\begin{enumerate}
    \item The majority of HBS values are small, corresponding to the brain appearing like a circle.
    \item The left side of the HBS has larger values, while the right side has smaller values, reflecting the brain's slightly tapered shape.
    \item HBS values exhibit scattered high values along the boundary, corresponding to the sulcus in the brain's outline. Note that the boundary of HBS is $\partial \D$ since it is always $0$ outside.
\end{enumerate}
The mean HBS preserves these features, but the boundary values which approach 1 become much less and only exist at the left and right ends. This is reflected in the image is a smoother outline, with distinct inward curvatures only at the division between the left and right halves of the brain. Because of that, we believe that mean HBS serves as a good shape prior.

It is worth mentioning that utilizing mean HBS as shape prior is not trivial even mean HBS is just the HBS of the mean shape. Becaus if you wanted to achieve a mean shape directly, you would need to align, resize, and orient the shapes based on certain feature points explicitly. Besides, the rationality and universality of these feature points are also crucial factors to consider. However, the mean HBS is a common and convenient method to extract shape prior with soild theoretical background.

\subsection{Segmentation of complex images}
With the help of the mean HBS, we can now apply our proposed segmentation model to complex images. Firstly, We take the mean HBS in last experiment and some new brains as an example. For each row in Figure \ref{exp6}, 1st column is the given brain, 2nd is the segmentation result without HBS, 3rd is the segmentation result guided by the HBS of unit disk and 4th is the segmentation result guided by the mean HBS in Figure \ref{exp5}.

\begin{figure}
    \begin{center}
        \includegraphics[width=15.5cm]{src/exp6.png}
    \end{center}
    \caption{Segmentation on brains guided by mean HBS.}
    \label{exp6}
\end{figure}

The brain in 1st row is quite similar with those we used to compute mean HBS in last experiment, leading that the result guided by mean HBS is almost prefect. The result guided by the HBS of unit disk loss some top and bottom region, maybe that makes it looks more like a circle. And the result without HBS has a very rough boundary and tends to discard regions with relatively discontinuous intensity, like the small part on left bottom of the object due to a deep sulcus. The brain in 2nd row has a pathological region in the left bottom corner and deviates from the common features we summarized. Therefore, the segmentation result with mean HBS is not satisfactory enough and it tries to make up the missing region. While the other 2 results appear similar features with 1st row.


%  as Figure \ref{exp4} shown. The 1st row consists of binary images of 4 animals, and the 2nd row shows their respective HBS.

% \begin{figure}
%     \begin{center}
%         \includegraphics[width=15.5cm]{src/exp4.png}
%     \end{center}
%     \caption{HBS of complex images of animals.}
%     \label{exp4}
% \end{figure}



\section{Conclusion}\label{conclusion}

\bibliographystyle{siamplain}       % APS-like style for physics
\bibliography{cite}
% Non-BibTeX users please use
% \begin{thebibliography}{}
% %
% % and use \bibitem to create references. Consult the Instructions
% % for authors for reference list style.
% %
% \bibitem{RefJ}
% % Format for Journal Reference
% Author, Article title, Journal, Volume, page numbers (year)
% % Format for books
% \bibitem{RefB}
% Author, Book title, page numbers. Publisher, place (year)
% % etc
% \end{thebibliography}

\end{document}
